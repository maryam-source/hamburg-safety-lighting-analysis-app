{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "VhtYSEFV9GyS",
        "outputId": "8388a49f-c5c1-435a-fd7c-d0558a69e971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "upload file\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-493006dd-440e-45c4-9490-84595dbe4e7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-493006dd-440e-45c4-9490-84595dbe4e7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving street-lamp-OSM.gpkg to street-lamp-OSM (1).gpkg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "rows: 100%|██████████| 6/6 [00:15<00:00,  2.52s/it]\n",
            "/tmp/ipython-input-536001957.py:268: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  meta_info={'created_at':datetime.datetime.utcnow().isoformat()+'Z',\n",
            "Reading input: lighting_model_highres_disk.tif\n",
            "\n",
            "Adding overviews...\n",
            "Updating dataset tags...\n",
            "Writing output to: lighting_model_highres_disk_cog.tif\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pipeline finished\n",
            "Raster: lighting_model_highres_disk.tif\n",
            "COG: lighting_model_highres_disk_cog.tif\n",
            "Vector grid: lighting_vector_grid_nonzero.gpkg\n",
            "Histogram: lighting_histogram.csv, lighting_histogram.png, lighting_histogram_log.png\n",
            "Metadata: lighting_metadata.json\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet geopandas rasterio shapely scipy matplotlib pyproj tqdm mapclassify rtree rio-cogeo rasterstats\n",
        "\n",
        "import os, json, math, logging, datetime\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "from rasterio.features import rasterize, shapes as rio_shapes\n",
        "from rasterio.windows import Window\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio.warp import reproject, Resampling as WarpResampling\n",
        "try:\n",
        "    from rasterio.enums import MergeAlg\n",
        "    _HAS_MERGEALG = True\n",
        "except Exception:\n",
        "    MergeAlg = None\n",
        "    _HAS_MERGEALG = False\n",
        "\n",
        "from shapely.geometry import shape as shapely_shape, Point\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
        "log = logging.getLogger(\"lighting_pipeline\")\n",
        "\n",
        "# upload lamp gpkg\n",
        "print(\"upload file\")\n",
        "uploaded = files.upload()\n",
        "if len(uploaded) == 0:\n",
        "    raise SystemExit(\"No file uploaded\")\n",
        "VECTOR_PATH = list(uploaded.keys())[0]\n",
        "log.info(f\"Uploaded: {VECTOR_PATH}\")\n",
        "\n",
        "# output files\n",
        "OUTPUT_RASTER = \"lighting_model_highres_disk.tif\"\n",
        "OUTPUT_COG = \"lighting_model_highres_disk_cog.tif\"\n",
        "VECTOR_GRID = \"lighting_vector_grid_nonzero.gpkg\"\n",
        "HIST_IMAGE = \"lighting_histogram.png\"\n",
        "HIST_LOG_IMAGE = \"lighting_histogram_log.png\"\n",
        "HIST_CSV = \"lighting_histogram.csv\"\n",
        "METADATA_JSON = \"lighting_metadata.json\"\n",
        "\n",
        "PIXEL_SIZE = 5\n",
        "GAUSSIAN_SIGMA_PIX = 10\n",
        "CHUNK_SIZE = 2000            # tile size in pixels\n",
        "GRID_CELL_SIZE = 50\n",
        "NORMALIZE_TOTAL = True       # preserve total lamp count\n",
        "NODATA_VALUE = -9999.0\n",
        "NBINS_HIST = 30\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# load and validate lamp gpkg\n",
        "lamps = gpd.read_file(VECTOR_PATH)\n",
        "log.info(f\"Loaded lamp points: {len(lamps)}; original CRS: {lamps.crs}\")\n",
        "\n",
        "TARGET_CRS = \"EPSG:25832\"\n",
        "if lamps.crs is None or lamps.crs.to_string() != TARGET_CRS:\n",
        "    log.info(f\"Reprojecting to {TARGET_CRS}\")\n",
        "    lamps = lamps.to_crs(TARGET_CRS)\n",
        "log.info(f\"Active CRS: {lamps.crs}\")\n",
        "\n",
        "if len(lamps) == 0:\n",
        "    raise SystemExit(\"ERROR: No lamp features found in input file.\")\n",
        "\n",
        "# check spatial index exists\n",
        "try:\n",
        "    _ = lamps.sindex\n",
        "    spatial_index = lamps.sindex\n",
        "except Exception:\n",
        "    spatial_index = None\n",
        "    log.warning(\"Spatial index unavailable; spatial queries slower.\")\n",
        "\n",
        "# raster grid metadata\n",
        "minx, miny, maxx, maxy = lamps.total_bounds\n",
        "pad_m = PIXEL_SIZE\n",
        "minx -= pad_m; miny -= pad_m; maxx += pad_m; maxy += pad_m\n",
        "\n",
        "width = int(math.ceil((maxx - minx)/PIXEL_SIZE))\n",
        "height = int(math.ceil((maxy - miny)/PIXEL_SIZE))\n",
        "transform = from_origin(minx, maxy, PIXEL_SIZE, PIXEL_SIZE)\n",
        "log.info(f\"Raster: width={width}, height={height}, transform={transform}\")\n",
        "\n",
        "if width <= 0 or height <= 0:\n",
        "    raise SystemExit(\"Invalid raster dimensions.\")\n",
        "\n",
        "def rasterize_additive(shapes_iter, out_shape, transform_local, dtype='uint32'):\n",
        "# Rasterize features additively\n",
        "    if _HAS_MERGEALG and MergeAlg is not None:\n",
        "        try:\n",
        "            return rasterize(\n",
        "                shapes=shapes_iter,\n",
        "                out_shape=out_shape,\n",
        "                transform=transform_local,\n",
        "                fill=0,\n",
        "                dtype=dtype,\n",
        "                merge_alg=MergeAlg.add\n",
        "            )\n",
        "        except TypeError:\n",
        "            pass\n",
        "    # fallback: loop per-shape\n",
        "    out = np.zeros(out_shape, dtype=dtype)\n",
        "    for geom, val in shapes_iter:\n",
        "        single = rasterize([(geom,val)], out_shape=out_shape, transform=transform_local, fill=0, dtype=dtype)\n",
        "        out += single\n",
        "    return out\n",
        "\n",
        "# chunked rasterization & gaussian smoothing\n",
        "log.info(\"Starting chunked additive rasterization + Gaussian smoothing...\")\n",
        "halo = int(math.ceil(3*GAUSSIAN_SIGMA_PIX))\n",
        "halo = min(halo, max(0, CHUNK_SIZE//2 - 1))\n",
        "log.info(f\"Halo (pixels): {halo}\")\n",
        "\n",
        "meta = {\n",
        "    'driver':'GTiff','height':height,'width':width,'count':1,\n",
        "    'dtype':'float32','crs':TARGET_CRS,'transform':transform,\n",
        "    'tiled':True,'blockxsize':CHUNK_SIZE,'blockysize':CHUNK_SIZE,\n",
        "    'compress':'lzw','BIGTIFF':'YES','nodata':NODATA_VALUE\n",
        "}\n",
        "\n",
        "with rasterio.open(OUTPUT_RASTER,'w',**meta) as dst:\n",
        "    burn_total_est = 0\n",
        "    for row_start in tqdm(range(0,height,CHUNK_SIZE), desc=\"rows\"):\n",
        "        for col_start in range(0,width,CHUNK_SIZE):\n",
        "            r0 = max(0,row_start-halo); c0=max(0,col_start-halo)\n",
        "            r1 = min(height,row_start+CHUNK_SIZE+halo)\n",
        "            c1 = min(width,col_start+CHUNK_SIZE+halo)\n",
        "            win_h = r1-r0; win_w = c1-c0\n",
        "            x0 = minx + c0*PIXEL_SIZE; x1 = minx + c1*PIXEL_SIZE\n",
        "            y1 = maxy - r0*PIXEL_SIZE; y0 = maxy - r1*PIXEL_SIZE\n",
        "\n",
        "            try:\n",
        "                idx = list(spatial_index.intersection((x0,y0,x1,y1)))\n",
        "            except Exception:\n",
        "                idx = list(lamps.index)\n",
        "            lamps_tile = lamps.iloc[idx]\n",
        "\n",
        "            count_arr = np.zeros((win_h,win_w),dtype='uint32')\n",
        "            if len(lamps_tile)>0:\n",
        "                shapes_iter = ((geom,1) for geom in lamps_tile.geometry)\n",
        "                burned = rasterize_additive(shapes_iter,out_shape=(win_h,win_w),\n",
        "                                            transform_local=from_origin(x0,y1,PIXEL_SIZE,PIXEL_SIZE),\n",
        "                                            dtype='uint32')\n",
        "                count_arr += burned\n",
        "\n",
        "            # Smooth\n",
        "            count_f = count_arr.astype('float32')\n",
        "            smoothed = gaussian_filter(count_f,sigma=GAUSSIAN_SIGMA_PIX,mode='constant',cval=0.0) if np.any(count_f) else count_f\n",
        "\n",
        "            # Write center chunk (exclude halo)\n",
        "            r_c0 = row_start - r0; c_c0 = col_start - c0\n",
        "            r_c1 = r_c0 + min(CHUNK_SIZE,height-row_start)\n",
        "            c_c1 = c_c0 + min(CHUNK_SIZE,width-col_start)\n",
        "            chunk_center = smoothed[r_c0:r_c1, c_c0:c_c1]\n",
        "\n",
        "            write_win = Window(col_start,row_start,chunk_center.shape[1],chunk_center.shape[0])\n",
        "            dst.write(chunk_center.astype('float32'),1,window=write_win)\n",
        "            burn_total_est += int(count_arr[r_c0:r_c1,c_c0:c_c1].sum())\n",
        "\n",
        "    dst.update_tags(lamp_count=len(lamps),pixel_size=PIXEL_SIZE,bounds=f\"{minx},{miny},{maxx},{maxy}\")\n",
        "log.info(f\"Rasterization + smoothing done -> {OUTPUT_RASTER}\")\n",
        "\n",
        "# build raster overviews\n",
        "with rasterio.open(OUTPUT_RASTER,'r+') as src:\n",
        "    factors = [2,4,8,16]; src.build_overviews(factors,Resampling.average)\n",
        "    src.update_tags(ns='rio_overview',resampling='average')\n",
        "log.info(\"Overviews built\")\n",
        "\n",
        "# stats & histogram\n",
        "def welford_update(count,mean,M2,data_array):\n",
        "    data = data_array.ravel()\n",
        "    mask = (data != NODATA_VALUE) & np.isfinite(data)\n",
        "    if not np.any(mask):\n",
        "        return count,mean,M2\n",
        "    x = data[mask].astype('float64')\n",
        "    for val in x:\n",
        "        count +=1; delta=val-mean; mean+=delta/count; delta2=val-mean; M2+=delta*delta2\n",
        "    return count,mean,M2\n",
        "\n",
        "count=0; mean=0.0; M2=0.0; min_val=np.inf; max_val=-np.inf; nonzero_pixels=0; total_pixels=0\n",
        "with rasterio.open(OUTPUT_RASTER) as src:\n",
        "    for _,window in src.block_windows(1):\n",
        "        data=src.read(1,window=window,boundless=True,fill_value=NODATA_VALUE)\n",
        "        total_pixels+=data.size\n",
        "        mask=(data!=NODATA_VALUE)&np.isfinite(data)\n",
        "        if np.any(mask):\n",
        "            values=data[mask]; nonzero_pixels+=int(np.count_nonzero(values>0))\n",
        "            min_val=min(min_val,float(np.nanmin(values))); max_val=max(max_val,float(np.nanmax(values)))\n",
        "            count,mean,M2=welford_update(count,mean,M2,data)\n",
        "variance=(M2/(count-1)) if count>1 else 0.0\n",
        "std=math.sqrt(variance) if variance>=0 else float('nan')\n",
        "stats={\"pixels_total\":int(total_pixels),\"pixels_with_data\":int(count),\"nonzero_pixels\":int(nonzero_pixels),\n",
        "       \"min\":float(min_val) if min_val!=np.inf else float('nan'),\n",
        "       \"max\":float(max_val) if max_val!=-np.inf else float('nan'),\n",
        "       \"mean\":float(mean),\"std\":float(std)}\n",
        "log.info(\"Raster stats computed (streaming):\")\n",
        "for k,v in stats.items(): log.info(f\"  {k}: {v}\")\n",
        "\n",
        "bins=np.linspace(stats['min'],stats['max'],NBINS_HIST+1) if np.isfinite(stats['min']) and np.isfinite(stats['max']) and stats['min']<stats['max'] else np.linspace(0,1,NBINS_HIST+1)\n",
        "hist_counts=np.zeros(len(bins)-1,dtype=np.int64)\n",
        "with rasterio.open(OUTPUT_RASTER) as src:\n",
        "    for _,window in src.block_windows(1):\n",
        "        data=src.read(1,window=window,boundless=True,fill_value=NODATA_VALUE)\n",
        "        mask=(data!=NODATA_VALUE)&np.isfinite(data)\n",
        "        if np.any(mask):\n",
        "            h,_=np.histogram(data[mask],bins=bins)\n",
        "            hist_counts+=h\n",
        "\n",
        "np.savetxt(HIST_CSV,np.c_[bins[:-1],bins[1:],hist_counts],delimiter=\",\",\n",
        "           header=\"bin_start,bin_end,count\",comments=\"\")\n",
        "centers=(bins[:-1]+bins[1:])/2.0; widths=(bins[1]-bins[0])\n",
        "plt.figure(figsize=(8,4)); plt.bar(centers,hist_counts,width=widths,edgecolor='black')\n",
        "plt.title(\"Lighting Intensity Histogram\"); plt.xlabel(\"Intensity\"); plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout(); plt.savefig(HIST_IMAGE,dpi=150); plt.close()\n",
        "plt.figure(figsize=(8,4)); plt.bar(centers,hist_counts,width=widths,edgecolor='black'); plt.yscale('log')\n",
        "plt.title(\"Lighting Intensity Histogram (log)\"); plt.xlabel(\"Intensity\"); plt.ylabel(\"Frequency (log)\")\n",
        "plt.tight_layout(); plt.savefig(HIST_LOG_IMAGE,dpi=150); plt.close()\n",
        "log.info(f\"Histogram saved: {HIST_CSV}, {HIST_IMAGE}, {HIST_LOG_IMAGE}\")\n",
        "\n",
        "# normalization\n",
        "if NORMALIZE_TOTAL:\n",
        "    lamp_count = len(lamps)\n",
        "    current_sum = 0.0\n",
        "    with rasterio.open(OUTPUT_RASTER) as src:\n",
        "        for _,window in src.block_windows(1):\n",
        "            data=src.read(1,window=window,boundless=True,fill_value=NODATA_VALUE)\n",
        "            mask=(data!=NODATA_VALUE)&np.isfinite(data)\n",
        "            if np.any(mask): current_sum+=float(np.sum(data[mask]))\n",
        "    if current_sum>0:\n",
        "        scale=float(lamp_count)/current_sum\n",
        "        log.info(f\"Normalizing raster by scale factor {scale:.6g}\")\n",
        "        with rasterio.open(OUTPUT_RASTER,'r+') as src:\n",
        "            for _,window in src.block_windows(1):\n",
        "                data=src.read(1,window=window,boundless=True,fill_value=NODATA_VALUE)\n",
        "                mask=(data!=NODATA_VALUE)&np.isfinite(data)\n",
        "                if np.any(mask): data[mask]*=scale; src.write(data.astype('float32'),1,window=window)\n",
        "\n",
        "\n",
        "# vector grid\n",
        "log.info(\"Aggregating raster to vector grid (non-zero cells)...\")\n",
        "scale = GRID_CELL_SIZE / PIXEL_SIZE\n",
        "agg_width = int(math.ceil(width/scale)); agg_height=int(math.ceil(height/scale))\n",
        "agg_transform = from_origin(minx,maxy,GRID_CELL_SIZE,GRID_CELL_SIZE)\n",
        "dst_agg = np.full((agg_height,agg_width),NODATA_VALUE,dtype='float32')\n",
        "with rasterio.open(OUTPUT_RASTER) as src:\n",
        "    reproject(source=rasterio.band(src,1),destination=dst_agg,\n",
        "              src_transform=src.transform,src_crs=src.crs,\n",
        "              dst_transform=agg_transform,dst_crs=src.crs,\n",
        "              resampling=WarpResampling.average,\n",
        "              src_nodata=NODATA_VALUE,dst_nodata=NODATA_VALUE)\n",
        "mask_valid=(dst_agg!=NODATA_VALUE)&np.isfinite(dst_agg)&(dst_agg>0)\n",
        "n_valid=int(np.count_nonzero(mask_valid))\n",
        "log.info(f\"Aggregated cells: {agg_width}x{agg_height} -> non-zero: {n_valid}\")\n",
        "if n_valid==0:\n",
        "    vg=gpd.GeoDataFrame({'mean_intensity':[],'geometry':[]},crs=TARGET_CRS)\n",
        "    vg.to_file(VECTOR_GRID,driver='GPKG')\n",
        "else:\n",
        "    results=[(geom,float(val)) for geom,val in rio_shapes(dst_agg,mask=mask_valid,transform=agg_transform)]\n",
        "    geoms=[shapely_shape(g) for g,v in results]; vals=[v for g,v in results]\n",
        "    vg=gpd.GeoDataFrame({'mean_intensity':vals,'geometry':geoms},crs=TARGET_CRS)\n",
        "    vg.to_file(VECTOR_GRID,driver='GPKG')\n",
        "    log.info(f\"Saved {len(vg)} polygons to {VECTOR_GRID}\")\n",
        "\n",
        "# metadata & COG\n",
        "meta_info={'created_at':datetime.datetime.utcnow().isoformat()+'Z',\n",
        "           'source_vector':VECTOR_PATH,'lamp_count':len(lamps),'target_crs':TARGET_CRS,\n",
        "           'pixel_size_m':PIXEL_SIZE,'gaussian_sigma_pixels':GAUSSIAN_SIGMA_PIX,\n",
        "           'gaussian_sigma_meters':GAUSSIAN_SIGMA_PIX*PIXEL_SIZE,'chunk_size_pixels':CHUNK_SIZE,\n",
        "           'grid_cell_size_m':GRID_CELL_SIZE,'normalize_total':bool(NORMALIZE_TOTAL),\n",
        "           'nodata_value':float(NODATA_VALUE),'histogram_bins':int(NBINS_HIST),'seed':int(SEED)}\n",
        "with open(METADATA_JSON,'w') as fh: json.dump(meta_info,fh,indent=2)\n",
        "log.info(f\"Metadata written to {METADATA_JSON}\")\n",
        "\n",
        "try:\n",
        "    from rio_cogeo.cogeo import cog_translate\n",
        "    from rio_cogeo.profiles import cog_profiles\n",
        "    profile=cog_profiles.get('deflate')\n",
        "    cog_translate(OUTPUT_RASTER,OUTPUT_COG,profile)\n",
        "    log.info(f\"COG created: {OUTPUT_COG}\")\n",
        "except Exception as e:\n",
        "    log.warning(f\"COG creation skipped/failed: {e}\")\n",
        "\n",
        "# verification & debuging\n",
        "burn_check = 0\n",
        "with rasterio.open(OUTPUT_RASTER) as src:\n",
        "    for row_start in range(0, height, CHUNK_SIZE):\n",
        "        for col_start in range(0, width, CHUNK_SIZE):\n",
        "            r0=row_start; c0=col_start\n",
        "            r1=min(height,row_start+CHUNK_SIZE)\n",
        "            c1=min(width,col_start+CHUNK_SIZE)\n",
        "            x0=minx+c0*PIXEL_SIZE\n",
        "            y1=maxy-r0*PIXEL_SIZE\n",
        "            idx = list(spatial_index.intersection((x0, maxy-r1*PIXEL_SIZE, minx+c1*PIXEL_SIZE, y1)))\n",
        "            lamps_tile = lamps.iloc[idx]\n",
        "            if len(lamps_tile)>0:\n",
        "                burned = rasterize_additive(((g,1) for g in lamps_tile.geometry),\n",
        "                                            out_shape=(r1-r0, c1-c0),\n",
        "                                            transform_local=from_origin(x0,y1,PIXEL_SIZE,PIXEL_SIZE),\n",
        "                                            dtype='uint32')\n",
        "                burn_check += int(burned.sum())\n",
        "log.info(f\"Burn test: rasterized count sum = {burn_check}, original lamp count = {len(lamps)}\")\n",
        "\n",
        "def synthetic_additive_test():\n",
        "    sminx=minx; smaxy=maxy\n",
        "    synth = gpd.GeoDataFrame({'geometry':[Point(sminx+10,miny+10),Point(sminx+12,miny+10),Point(sminx+11,miny+12)]},crs=TARGET_CRS)\n",
        "    out = rasterize_additive(((g,1) for g in synth.geometry), out_shape=(50,50),\n",
        "                              transform_local=from_origin(sminx,smaxy,PIXEL_SIZE,PIXEL_SIZE))\n",
        "    return int(out.sum())==len(synth)\n",
        "synth_ok = synthetic_additive_test()\n",
        "log.info(f\"Synthetic additive test passed: {synth_ok}\")\n",
        "\n",
        "print(\"\\nPipeline finished\")\n",
        "print(f\"Raster: {OUTPUT_RASTER}\")\n",
        "print(f\"COG: {OUTPUT_COG}\")\n",
        "print(f\"Vector grid: {VECTOR_GRID}\")\n",
        "print(f\"Histogram: {HIST_CSV}, {HIST_IMAGE}, {HIST_LOG_IMAGE}\")\n",
        "print(f\"Metadata: {METADATA_JSON}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQkSURptMPah",
        "outputId": "7df6b9cb-2d01-4efe-8c2d-ad140d72f1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-zero raster bounds: 466973.9,5919957.0 to 588248.9,5974427.0\n"
          ]
        }
      ],
      "source": [
        "# analyze non-zero raster area & suggest polygon\n",
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape, box\n",
        "\n",
        "RASTER_FILE = \"lighting_model_highres_disk.tif\"\n",
        "VECTOR_GRID = \"lighting_vector_grid_nonzero.gpkg\"\n",
        "OUTPUT_POLYGON = \"nonzero_raster_area.gpkg\"\n",
        "\n",
        "# load raster and compute non-zero bounds\n",
        "with rasterio.open(RASTER_FILE) as src:\n",
        "    data = src.read(1, masked=True)  # masked array ignores nodata automatically\n",
        "    mask = data > 0\n",
        "    if mask.any():\n",
        "        rows, cols = mask.nonzero()\n",
        "        min_row, max_row = rows.min(), rows.max()\n",
        "        min_col, max_col = cols.min(), cols.max()\n",
        "        minx, maxy = src.xy(min_row, min_col)\n",
        "        maxx, miny = src.xy(max_row, max_col)\n",
        "        print(f\"Non-zero raster bounds: {minx:.1f},{miny:.1f} to {maxx:.1f},{maxy:.1f}\")\n",
        "        suggested_poly = box(minx, miny, maxx, maxy)\n",
        "    else:\n",
        "        raise SystemExit(\"Raster has no non-zero values.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
